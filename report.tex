\documentclass[11pt]{article}
\usepackage{a4, fullpage}
\usepackage{bibtopic}
%\usepackage[small,compact]{titlesec}
\usepackage{float}
\usepackage{amssymb,amsmath}
\usepackage[T1]{fontenc}
\usepackage{graphicx}
\usepackage{multicol}
\restylefloat{table}
%\usepackage{parskip}
%\usepackage{setspace}

%\setlength{\parskip}{0.3cm}
%\setlength{\parindent}{0cm}
%\setlength{\textheight}{10in}
%\setlength{\textwidth}{6.5in}
%\setlength{\parskip}{2pt}
%\addtolength{\oddsidemargin}{-.3in}
%\addtolength{\evensidemargin}{-.3in}
%\addtolength{\topmargin}{-.6in}
%\addtolength{\textwidth}{.6in}

%Crowdsourcing of tasks has become very popular. It is often based on the principle that by having many different contributors to performing a task, an accurate and appropriate result will be achieved. The classical example is wikipedia where popular pages tend to be more accurate than less popular one. But contributions to a task do not always come for free and frameworks such as Amazon's mechanical turk allow for monetary rewards to be paid in exchange for contributing or performing a task. It is therefore the case that fewer contributions from more trustworthy contributors is more effective than many contributions from less trustworthy sources. 

%The aim of the project is to design and implement a framework that allows the optimum number of contributors to be selected on the basis of their trustworthiness for a desired accuracy of the outcome/result and that evaluates the trustworthiness of contributors on the basis of the accuracy of the results they provide.


\begin{document}



\title{Crowdtrust - Trustworthy Information From The Crowd\\ Group Project }

\author{Giovanni Charles \and Adam Fiksen \and Ryan Jackson \and Sahil Jain \and John Walker \and \\ Emil Lupu}

\date{\today}         % inserts today's date

\maketitle           % generates the title from the data above
\newpage

\begin{abstract}
\noindent Outsourcing is becomming increasingly popular in a lot of areas and as a result providing these required services has 
become big business. Companies are using the Internet to accept jobs from requestors which often require some human intelligence 
such as tagging images, they then distribute these jobs to a crowd of workers and return the results to the requestor. This process is called
crowdsourcing. %Not happy with this
\\
\\
\noindent At the moment Amazons \emph{Mechanical Turk} is the only real crowdsourcing `giant' in the market, with over 500,000 workers it offers
anyone with a computer and internet connection the ability to `earn \$\$\$ while working from home!'. Requestors (companies or individuals) 
can then submit a HIT(Human Intelligence Task) to the mechanical turk system, this HIT is then displayed to all users along with a 
reward for its completion, the results are then sent back to the requestor and they decide whether the work is worth paying for. 
This system raises a problem though, How do I know how accurate my results are? You have no control over which worker selects your HIT and
your task of 'Transcribe this podcast' could be carried out by a lacklustre employee in India who doesn't speak very good English. The solution
most requestor guides offer is to submit your job to multiple workers but this pushes up your costs linearly and leaves you to make a difficult
decision to make on the number of workers to consult.
\\
\\
We seek to create is a solution to this problem by providing a framework in which requesters can submit jobs with a required level of accurary. Our
system then decides how many users it needs to consult to achieve this based on their expertise. 
  
\end{abstract}

\newpage

\tableofcontents	%Do contents page and a 1 page break afterward

\newpage

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Executive Summary}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}
%Set the scene ( motivation )
%State the problem you are trying to solve ( Ojective(s) )
%Summarise what you achieved ( contributions )
%%%%%%%%%%%
\subsection{What Is Crowdsourcing} %Change the I adam and 'I' will kill you
Our project concerns \emph{crowdsourcing} 'the book' would describe crowdsourcing as the principle of obtaining an accurate 
and appropriate result by having many different contributors performing a task but we'd like to start with a story which
we believe encapsulates the idea of crowdsourcing in its most positive and useful light.
\\
\\
In January 2009 Timothy Gowers (Fields Medal winner and avid blogger) used his blog to post a striking question \emph{Is massively 
collaborative mathematics possible?}. He posted a difficult and unsolved mathematical problem he was particularly interested in and invited 
people to contribute to its solution in the comments section. The project initally got off to a slow start but once the ice was broken the 
comments flooded in. 37 days , 27 contibuters and 800 comments later Timothy Gowers was able to announce that not only had they solved the 
original problem but they had also solved a harder generalisation of it, he called his experiment the \emph{Polymath Project} .
\\
\\
This is a nice example of how crowd sourcing can be used to combine the skills of many individuals and produce answers to a complex problems,
but there are many motivations to outsource your task to the crowd:
\begin{itemize}
\item
\emph{Computational Difficulty:} Timothy Gowers provided a nice example of a computationally difficult problem It is extememly unlikely you
would be able to write a Java program or use Wolphram Alpha to produce a complex mathematical proof, some problems require what we like to call
the 'human touch'. Problems which require the human touch are in no way confined to the realms of complex mathematics identifing an unknown
bird in a picture for example would prove quite difficult on a computer you may need access some a program like Google Goggles but even then you 
would probablly need a good quality photograph, whereas one avid bird enthusiast in the crowd might be able to easilly identify the bird and
reuturn the correct answer.
\item
\emph{Saving Time:} In 2009 aviator Steve Fosset crash landed deep in the Nevada desert, his friends knew they had a very small
and time critical window to find him alive and they had little faith in the current search and resuce operations. They organised for satellite 
images to be taken of the desert and the images were passed to a crowd who were asked to identify foreign object which could be potential crash 
sites. This is a nice example of how the crowd can be used to literally cover a large ammount of ground in a small ammount of time. Not all 
examples of saving time are quite this dramatic though, image tagging is an extemely arduous task for an individual or small group of people 
to perform and tagging a relatively large set of images could take weeks or even months, outsourcing this to the crowd could have the job 
done in a number of hours.
\item
\emph{Saving Money:} Time is money as they say and this goes hand it hand with the point above. If you have to pay a team of high salary computing
professionals to tag images for your project when you could be paying them to write code this is not cost effective, however passing this job off
to a crowd of lower paid people could potentially save you a lot of money. 
\item
\emph{Reaching A Willing Audiance:} Unless it's something they enjoy the fact is that people are not willing to work for free, this is why
getting the general public to do things such as complete surverys can be difficult as a large number of people will simply not want to do it. The
crowd memebers will be inventivised to perform work and as such will be more likely to complete your survey.
\end{itemize}
%%%%%%%%%%%
\subsection{Analysis of the Marketplace}

%%%%%%%%%%%
\subsection{Problem Description}
\begin{enumerate}
\item
\emph{How do we get these problems to the crowd?} 
\\
It is unlikely many people with a problem to be solved would want to go to the trouble
of creating a crowd themselves as this would be comparitive to the complexity of the problem itself therefore there is a need for a third party
crowd management system. 
\item
\emph{What problems can we ask the crowd?} 
\\
Specialised crowds have been successful and certainly have their uses for instance\\
www.stackoverflow.com can be thought of as a crowd specialising in the solution of computing problems, however it is unlikely I would
be able to find a specialised crowd to indentify bird pictures or to search satellite images for crash sites, therefore I need access 
to a generalised crowd able to adapt to and solve a wide variety of problems. The crowd management party therefore needs to provide
the ability to ask a wide variety of questions and the ability to easily encorporate new questions in response to new technology. %EMBELISH?
\item
\emph{How many people do we ask, who do we ask and how can we trust what they say?} 
\\
Crowd members will be a representitive sample of the general 
population, some will be brighter than others and some will be willing to put in more effort than others based on this you can place all 
annotators on a scale of trustworthiness which rates how much you believe an answer they give you. This rasises the question of 'how many 
people do I ask?', is consulting a small number of very trustworthy people better than a large number of non trustworthy people?, However I 
can't simply ask the same subset of people over and over again as workload will build up and my answers will be delayed. If I have a 
'specialist' question do I direct it to someone with knowledge of that specialism? Clearly a sophisticated algorithm is needed on the crowd
management side to address these problems. 
\end{enumerate}
A solution to these problems provides us with the basis for our project we are to:
\\
\\
\emph{Design and implement a framework that allows the optimum number of contributors to be selected on the basis of their trustworthiness 
for a desired accuracy of the outcome/result and that evaluates the trustworthiness of contributors on the basis of the accuracy of the 
results they provide.}
%%%%%%%%%%%
\subsection{Formal Objectives}
%%%%%%%%%%%
\subsection{Achievements}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Design and Implementation}
% Detail your design why did you do it this way?
%Summarise Key implementation details (how did you do it what 
%tools did you use

\subsection{Data Processing}

Once clients have submitted their tasks and the crowd are submitting answers, our goals are:
\begin{enumerate}
\item To estimate the correct annotation for each subtask based on crowd annotations and their respective likelihoods of being correct.
\item To use crowd annotations to better our understanding of the accuracy of a crowd
\end{enumerate}

These goals can be achieved with the `Expectation-Maximisation algorithm'. We have adopted this algorithm for the processing of annotations, generalised it to work over a variety of task types and implemented it to function efficiently in an online environment.\\

\subsubsection{EM-Algorithm overview}

The a EM algorithm models the system as a hypothesis, h, and new evidence, Y, which is a set independent instances with observed data, X, and unobserved data, Z.\\

For our particular case we have a set of subtasks, S, with correct annotations, $Z_{s}$; a set of annotators, J, with accuracies $A_{j}$ and labels $L_{ij}$ from these annotators to subtasks

It then iterates through two steps to revise this hypothesis so that it converges on the most likely hypothesis for the state of the system.\\

Expectation Step:\\
You calculate P(Z) values using the X assuming the current hypothesis holds. In our case Z are the correct annotations for each subtask, X are the provided labels and the current hypothesis is the annotator`s accuracy. [1]\\

$ p(z_{i}) = p(z_{i}|\zeta) \prod p (l_{ij} | z_{i} a_{j}) $ (1)\\

where $p(z|\zeta)$ is our prior belief of $p(z)$.\\

Maximisation Step:\\
You replace the current hypothesis h with the most likely hypothesis assuming that the Z = E[Z]. This will mean that we have to calculate our most likely accuracies for the system based on the expected correct annotations calculated from the previous step.\\

$ Q(a_{j},a\prime_{j}) = \log p(a_{j}|\alpha_{j}) + \sum E_{z_{i}} [\log p (l_{ij} | z_{i} a_{j})]$ (2)\\

\subsubsection{Annotation types}

Our framework deals with a variety of subtasks that have different annotation types and models for accurate behaviour.\\

We model each of the subtasks with a different conjugate prior and model for accurate behaviour.\\

%\renewcommand{\arraystretch}{1.5}
\begin{table}[htdp]
\caption{Subtask models [2]}
\begin{center}
\begin{tabular}{|p{2cm}|p{5cm}|p{4cm}|p{4cm}|}
Subtask type & Description & conjugate prior & likelihood \\
\hline
Binary & An annotator can respond either true or false & $Beta(\alpha_{j}^{0}, \beta_{j}^{0})Beta(\alpha_{j}^{1},\beta_{j}^{1})$, where $\alpha_{j}^{0/1}$ are the negative and positive successes and $\beta_{j}^{0/1}$ are the failures.& $p(l_{ij} = z_{i} = 1 | a_{j}) = a_{j}^{1}$ $p(l_{ij} = z_{i} = 0 | a_{j}) = a_{j}^{0}$\\ [2cm]

Multivalued & An annotator must categorise the subject into one of a range of categories D & $Beta(\alpha, \beta)$, where $\alpha$ is the number of successes and $\beta$ the failures.  &  $p(l_{ij} = z_{i}| a_{j}) = a_{j}$ $p(l_{ij} \ne z_{i} | a_{j}) = \frac{1 - a_{j}}{D - 1}$\\ [1cm]

Continuous & An annotator must respond using a tuple from an N-dimensional number line & as above &  $p(l_{ij} | z_{i} a_{j}) = a_{j} p(l_{ij}|honest) + (1- a_{j}) p(l_{ij}|random)$, where the probability of an honest label is given by $\mathcal{N}(l_{ij}, \sum)$ for a given variance and the random probability is uniform over the response space.\\
\end{tabular}
\end{center}
\label{models}
\end{table}

\subsubsection{Online Considerations}

The online implementation of this algorithm is different in that it does not compute the expected labels as a batch job but instead has to observe several instances, one at a time, over a long period of time.\\

It also exploits discrimination. Expert annotators are asked first to respond to subtasks in order to reduce the total number of labels required. Since experts are likely to be the minority this technique is important since it makes sure that their annotations are taken into account [3].\\

We carry this out by checking the variance of our estimate for the most likely accuracy of an annotator. A large variance would suggest that we do not yet have enough information to judge an annotator. When the variance is small enough, we will test the accuracy against the criteria below.\\

\begin{table}[htdp]
\caption{default}
\begin{center}
\begin{tabular}{|c|c|}
Subtask type & criteria\\ \hline
Binary & \shortstack{$\frac{\Phi^{-1}(a_{j}^{0}) - \Phi^{-1}(1 - a_{j}^{1})}{2} > 2$ \\ i.e an annotator's sensitivity index [1] is greater than 2}\\
Multivalued & $a_{j} > 0.85$\\ 
Continuous & $a_{j} > 0.85$\\
\end{tabular}
\end{center}
\label{default}
\end{table}%

\subsubsection{Implementation details}

E-step
Db response > Update ratios > check threshold \& max labels >

M-step
Update accuracies > check threshold variance > update bot/expert lists

E step\\

To calculate (1), values for the Sequential Probability Ratio Test [4] for each hidden value Z are stored in the database. Since the value is the sum of a sequence, the stored value can simply be increased by the new value. At this point each value is tested with the threshold to see if the maximum likelihood is great enough. At this point the M step will begin.\\

M step\\

To compute the new accuracy (2), the prior accuracy needs to be modelled as a distribution stated in figure 1 and the expected accuracy is calculated assuming the correct label is the most likely one from the last step.\\

The new accuracy would be the peak of the equation (2). To avoid using numerical methods to estimate the peak we write the Bayes estimate as a convex combination of the prior and the data [5]. This way we get a formula for the expected accuracy that can be computed in constant time:\\

\begin{table}[htdp]
\caption{Bayes estimate}
\begin{center}
\begin{tabular}{|c|c|c|}
Subtask type & Convex combination & $\theta_{mle}$\\ \hline

Binary & $ E(a_{j}^{k}) = \gamma \frac{\alpha_{j}^{k}}{\alpha_{j}^{k} + \beta_{j}^{k}} +  (1 - \gamma)\theta_{mle}$, only for affected k & 1 if $l_{ij} = z_{i}$, 0 otherwise\\

Multivalued & $ E(a_{j}) = \gamma \frac{\alpha_{j}}{\alpha_{j} + \beta_{j}} +  (1 - \gamma)\theta_{mle}$ &1 if $l_{ij} = z_{i}$, 0 otherwise\\

Continuous & $ E(a_{j}) = \gamma \frac{\alpha_{j}}{\alpha_{j} + \beta_{j}} +  (1 - \gamma)\theta_{mle}$ & \shortstack{$\frac{\mathcal{N}(l_{ij}| z_{i}, \sum)}{\mathcal{N}(l_{ij}| z_{i}, \sum) + \lambda^{-1}}$ \\ where $\lambda$ is the response space}\\
\end{tabular}
\end{center}
\label{def}
\end{table}%

where $\gamma = \frac{\alpha_{j}^{k} + \beta_{j}^{k}}{\alpha_{j}^{k} + \beta_{j}^{k} + 1}$ 

Once the accuracies have been updated we must check the variance of the posterior accuracy. In the cases where the accuracy is modelled as a single beta distribution, multi valued and continuous, is trivial:\\

In the binary case the accuracy is modelled as a product of two dependant distributions therefore the variance must be estimated. We fit the peak to a multivariate Gaussian curve to estimate the posterior’s variance.\\

If we are confident in our knowledge of the annotator we test its accuracy against the criteria and store any new data about experts and bots in the database.\\

%[1] – Machine Learning Tom M Mitchell
%[2] - A Compendium of Conjugate Priors - John D. Cook
%[3] – Online crowdsourcing: rating annotators and obtaining cost-effective labels - Welinder Perona
%[4] - Sequential tests of statistical hypotheses – Wald
%[5] – Bayesian inference for simple problems - Simon Jackman
 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% 
\section{Evaluation}
%summarise testing procedures (+ relevant testing results)
%Evaluate your deliverables in terms of performance usability
%usefulness, (how successful was the project?)

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Conclusion and Future Extensions}
%Say what you've concluded from doing the work and how you'd build on it

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Project Management}
%Planning, group organisation, breakdown + task allocation etc

\subsection{Collaboration Tools}

In order to complete the project, we have made use of several tools which have
allowed us to collaborate our work efficiently. These are discussed below.

\begin{enumerate}
\item Git - Git was used as our version control system. All of us had previously
used git, so we were comfortable using it. Besides familiarity, there were
many other points which encouraged us to use git instead of other version control
systems. Firstly, since we would be working in several different places, such as
at home and in labs, we wanted a decentralised repository, which was provided
by using git. Git also allowed us to branch from the master branch when we were
working on something new, which was very convenient. Code from branches was
merged with the master branch only after thorough testing of the code.
\item Github - We used Github to track the progress of our project over the course
of the project development. Being able to read our detailed commit messages
allowed us to know where everyone was at with their part of the project. Again,
as with git, Github was available to us anywhere, so that was an added advantage
for using it.
\item Google+ - Since the progress of our project slowed down towards the end
of term due to coursework deadlines and Christmas tests, we planned to complete
our project over the Christmas break. During this time, communication was going
to be a problem as all of us were in different places. To tackle this problem,
we decided to have regular meetings on Google Plus. We would have them every 2
days, where we would discuss what we had accomplished, and what we would be working
on next. At the end, it worked out really well.
\item Skype, IM - At points, people would be working in pairs and such, so using
these means of communication were useful as we could not be present with one
another at all times.
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Appendix}
%e.g user guide

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{thebibliography}{9}

\end{thebibliography}

\end{document}

